# simple-rag
다음은 소스 코드의 간단한 설명과 사용법을 담은 `readme.md` 파일 예시입니다:

---

# FAISS 기반 문서 검색 시스템

이 프로젝트는 `sentence-transformers/all-MiniLM-L6-v2` 사전 훈련된 임베딩 모델을 사용하여 문서를 임베딩하고, FAISS(Facebook AI Similarity Search)를 이용해 텍스트 쿼리에 대해 유사한 문서를 검색하는 시스템입니다.

## 프로젝트 구성

이 시스템은 주어진 문서를 벡터화(임베딩)하여, 사용자가 입력한 쿼리와 유사도가 높은 문서를 빠르게 검색하는 데 목적이 있습니다. FAISS 라이브러리를 통해 벡터를 저장하고 검색을 수행합니다.

## 주요 기능

- **문서 임베딩**: 텍스트 데이터를 임베딩 벡터로 변환하여 벡터 공간에 저장합니다.
- **FAISS 검색**: 사용자가 입력한 쿼리를 임베딩한 후, 사전에 저장된 문서 임베딩과 비교하여 가장 유사한 문서를 반환합니다.

## 설치 방법

### 1. 필수 라이브러리 설치
먼저, 프로젝트에서 사용할 패키지를 설치합니다. 다음 명령어로 필요한 라이브러리를 설치하세요.

```bash
pip install faiss-cpu torch transformers numpy
```

### 2. 모델 다운로드
프로그램은 Hugging Face의 `sentence-transformers/all-MiniLM-L6-v2` 모델을 사용합니다. 처음 실행 시 모델이 자동으로 다운로드됩니다.

## 사용 방법

### 1. 샘플 문서 구성
프로젝트에서는 기본적으로 10개의 문서가 제공되며, 이를 FAISS 인덱스에 저장하여 검색에 활용합니다.

### 2. 검색 쿼리 입력
사용자는 텍스트로 질문(쿼리)을 입력하면, 시스템은 해당 쿼리에 가장 유사한 문서를 반환합니다. 예시:

```python
query = "귀사의 사업장의 위치는 어디입니까?"
```

이 쿼리에 대해 FAISS는 저장된 문서 중에서 가장 유사한 문서를 찾아서 반환합니다.

### 3. 실행 방법
소스 코드를 실행하면 사전 정의된 문서 코퍼스가 FAISS 인덱스에 저장되고, 사용자가 입력한 질의에 대한 유사 문서가 출력됩니다.

```bash
python main.py
```

실행 결과는 다음과 같습니다:

```plaintext
사용자의 질의: 귀사의 사업장의 위치는 어디입니까?
검색된 문서: ['회사는 서울시 강남구 테헤란로에 위치하고 있으며, 12층에 있습니다.', '저희 본사는 부산에 위치하고 있으며, 추가 지점은 전국에 걸쳐 있습니다.']
```

## 코드 설명

1. **텍스트 임베딩**: `generate_embedding()` 함수는 입력된 텍스트를 `AutoTokenizer`와 `AutoModel`을 통해 임베딩 벡터로 변환합니다.
2. **FAISS 인덱스 생성**: 변환된 문서 임베딩 벡터를 `faiss.IndexFlatL2()`에 저장하여 검색을 위한 인덱스를 만듭니다.
3. **문서 검색**: 사용자가 입력한 쿼리를 임베딩하여 FAISS 인덱스에서 유사한 문서를 검색하고, 가장 가까운 두 개의 문서를 반환합니다.

## 참고 사항

- 기본적으로 `sentence-transformers/all-MiniLM-L6-v2` 모델은 384차원의 임베딩을 생성하며, 다양한 언어를 처리할 수 있는 다국어 모델입니다.
- 이 시스템은 기본적으로 CPU에서 동작하지만, GPU에서의 성능 최적화를 위해 `faiss-gpu`와 같은 라이브러리를 사용할 수 있습니다.

## 라이선스
MIT License

---

이 문서는 사용자가 프로젝트를 빠르게 이해하고 실행할 수 있도록 돕기 위한 간단한 설명과 사용법을 포함하고 있습니다.
